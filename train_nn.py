# -*- coding: utf-8 -*-
"""train_nn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1romOnEi6boNF5e3wxdgtfMzwR127FANu
"""

from google.colab import drive
drive.mount('/content/drive')

# import sys
# sys.path.append('/content/drive/My Drive/Stance Detection')
# !pip install transformers

import torch
if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")

print(device)

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

"""**Stance description**

* unrelated: 0
* disagree: 1
* agree: 2
* discuss: 3

"""

import torch.nn as nn
import torch.nn.functional as F
from nn_model import Classifier
from nn_model import ConvEmbed
from generate_embeddings import DatasetIterator
from torch.optim import AdamW
from torch.optim import lr_scheduler
import tqdm
from math import ceil
import time
import torch

def train_dist_embeddings(model, neg_idx, PATH, ep):
  loss_plot = []
  epochs_plot = []
  accuracy_plot = []
  val_accuracy_plot = []
  val_loss_plot = []

  model.to(device)
  triplet_loss = nn.TripletMarginLoss(reduction='sum')
  optimizer = AdamW(model.parameters(), lr=3e-5, eps=1e-8)
  scheduler = lr_scheduler.StepLR(optimizer, step_size=ceil(ep/2), gamma=0.1)

  PATH_TRAIN_STANCES = '/content/drive/My Drive/Stance Detection/dataset/train_stances.csv'
  PATH_TRAIN_BODIES = '/content/drive/My Drive/Stance Detection/dataset/train_bodies.csv'

  epochs = ep
  train_data_size = 2250
  progress = tqdm.tqdm(total=train_data_size*epochs, position=0, leave=True)

  for epoch in range(epochs):
    for mode in ['Train', 'Validation']:
      running_loss = 0
      iterations = 0
      if mode == 'Train':
        d = DatasetIterator(PATH_TRAIN_STANCES, PATH_TRAIN_BODIES, True, 0, train_data_size)
      else:
        d = DatasetIterator(PATH_TRAIN_STANCES, PATH_TRAIN_BODIES, True, train_data_size)
      while True:
        if mode == 'Train':
          model.zero_grad()
          optimizer.zero_grad()
          dataloader = d.next(progress, neg_idx)
        else:
          dataloader = d.next(neg_idx=neg_idx)

        if dataloader is None:
          break

        for body_id, headEmbedding, bodyEmbedding, stance, headline_id in dataloader:
          body = bodyEmbedding.squeeze().to(device)
          head = headEmbedding.squeeze().to(device)

          stance = stance.squeeze(0)
          
          positives = []
          negatives = []

          for idx in range(len(stance)):
            if stance[idx] == neg_idx:
              negatives.append(head[idx].unsqueeze(0))
            elif stance[idx] > neg_idx:
              positives.append(head[idx].unsqueeze(0))

          # if len(negatives) == 1:
          #   model.eval()
          # else:
          #   model.train()

          body = body.repeat(len(negatives), 1, 1, 1).to(device)
          negative = torch.stack(negatives).to(device)
            

          for positive in positives:
            if mode == 'Train':
              model.zero_grad()
              optimizer.zero_grad()

            positive = positive.repeat(len(negatives), 1, 1, 1).to(device)
            iterations += len(negatives)

            if mode == 'Train':
              anchor_output = model(body)
              positive_output = model(positive)
              negative_output = model(negative)
            else:
              model.eval()
              with torch.no_grad():
                anchor_output = model.forward(body)
                positive_output = model.forward(positive)
                negative_output = model.forward(negative)

            assert anchor_output.shape == positive_output.shape == negative_output.shape

            loss = triplet_loss(anchor_output, positive_output, negative_output)

            if mode == 'Train':
              loss.backward()
              optimizer.step()

            running_loss += loss.item()

      if mode == 'Train':
        print(f"\nEpoch : {epoch}")
        print(f"Training Iterations : {iterations}")
        print(f"Training loss : {running_loss} / {iterations}:", running_loss / iterations, '\n')
        epochs_plot.append(epoch)
        loss_plot.append(running_loss / iterations)
        scheduler.step()
      else:
        print(f"\nValidation Iterations : {iterations}")
        print(f"Validation loss : {running_loss} / {iterations}:", running_loss / iterations, '\n')
        val_loss_plot.append(running_loss / iterations)

  torch.save(model.state_dict(), PATH.format(neg_idx))
  return epochs_plot, loss_plot, val_loss_plot

def train_logistic_regression(model, neg_idx, PATHS, PATHL, ep, dist):
  loss_plot = []
  epochs_plot = []
  accuracy_plot = []
  val_accuracy_plot = []
  val_loss_plot = []

  siamese = ConvEmbed()
  siamese.load_state_dict(torch.load(PATHS.format(neg_idx), map_location=device))
  siamese.to(device)
  siamese.eval()

  model.to(device)
  model.train()
  optimizer = AdamW(model.parameters(), lr=0.01)
  scheduler = lr_scheduler.StepLR(optimizer, step_size=ceil(ep/2), gamma=0.3)

  PATH_TRAIN_STANCES = '/content/drive/My Drive/Stance Detection/dataset/train_stances.csv'
  PATH_TRAIN_BODIES = '/content/drive/My Drive/Stance Detection/dataset/train_bodies.csv'

  epochs = ep
  train_data_size = 2250
  progress = tqdm.tqdm(total=train_data_size*epochs, position=0, leave=True)

  for epoch in range(epochs):
    for mode in ['Train', 'Validation']:
      running_loss = 0
      iterations = 0
      correct = 0
      pos_total = 0
      neg_total = 0
      pos = 0
      neg = 0
      total = 0
      if mode == 'Train':
        d = DatasetIterator(PATH_TRAIN_STANCES, PATH_TRAIN_BODIES, dist, 0, train_data_size)
      else:
        d = DatasetIterator(PATH_TRAIN_STANCES, PATH_TRAIN_BODIES, False, train_data_size)
      while True:
        if mode == 'Train':
          dataloader = d.next(progress, neg_idx)
        else:
          dataloader = d.next(neg_idx=neg_idx)

        if dataloader is None:
          break

        for body_id, headEmbedding, bodyEmbedding, stance, headline_id in dataloader:
          body = bodyEmbedding.squeeze().to(device)
          head = headEmbedding.squeeze(0).to(device)

          if mode == 'Train':
            model.zero_grad()
            optimizer.zero_grad()
          # print(negativePooler.shape)
          body = body.repeat(stance.shape[1], 1, 1, 1).to(device)
          head = head.unsqueeze(1)

          label = torch.bitwise_xor(torch.ge(stance, neg_idx), torch.eq(stance, neg_idx)).float()
          label = torch.transpose(label, 0, 1)
          pos_total += torch.sum(torch.eq(label, 1)).item()
          neg_total += torch.sum(torch.eq(label, 0)).item()
          total += stance.shape[1]
          if neg_idx == 1:
            wt = torch.where(label == 0, 2.7, 1.)
          else:
            wt = torch.where(label == 0, 1., 1.)
          bce_loss = nn.BCELoss(weight=wt, reduction='sum')

          with torch.no_grad():
            embed1 = siamese.forward(body)
            embed2 = siamese.forward(head)
          # print('Negative:')
          # print(cos(embed1, embed2))
          # dist = []
          # for i in range(embed1.shape[0]):
          #   dist.append(torch.dist(embed1[i], embed2[i]))
          # print(torch.as_tensor(dist))
          if mode == 'Train':
            output = model(embed1, embed2)
          else:
            model.eval()
            with torch.no_grad():
              output = model.forward(embed1, embed2)
          loss = bce_loss(output, label)
          # print(loss)
          # print(stance)
          # print(label)

          if mode == 'Train':
            loss.backward()
            optimizer.step()

          running_loss += loss.item()
          output[output >= 0.5] = True
          output[output < 0.5] = False

          with torch.no_grad():
            correct += torch.sum(torch.eq(output, label)).item()
            pos += torch.sum(torch.bitwise_and(output.bool(), label.bool())).item()
            neg += torch.sum(torch.bitwise_and(torch.bitwise_not(output.bool()), torch.bitwise_not(label.bool()))).item()
          iterations += 1

      if mode == 'Train':
        print(f"\nEpoch : {epoch}")
        print(f"Training loss : {running_loss} / {total}", running_loss / total)
        print(f"Accuracy : {correct} / {total} : ", correct / total)
        print(f"Accuracy Pos : {pos} / {pos_total} : ", pos / pos_total)
        print(f"Accuracy Neg : {neg} / {neg_total} : ", neg / neg_total)
        epochs_plot.append(epoch)
        accuracy_plot.append(correct / total)
        loss_plot.append(running_loss / total)
        scheduler.step()
      else:
        print(f"\nValidation loss : {running_loss} / {total} :", running_loss / total)
        print(f"Validation Accuracy : {correct} / {total} : ", correct / total)
        print(f"Accuracy Pos : {pos} / {pos_total} : ", pos / pos_total)
        print(f"Accuracy Neg : {neg} / {neg_total} : ", neg / neg_total)
        val_accuracy_plot.append(correct / total)
        val_loss_plot.append(running_loss / total)

  torch.save(model.state_dict(), PATHL.format(neg_idx))
  return epochs_plot, accuracy_plot, loss_plot, val_accuracy_plot, val_loss_plot

import matplotlib.pyplot as plt 

def plot(epochs_plot, loss_plot, val_loss_plot, accuracy_plot=None, val_accuracy_plot=None):
  if accuracy_plot is not None and val_accuracy_plot is not None:
    plt.plot(epochs_plot, accuracy_plot, label = "Accuracy plot")
    plt.plot(epochs_plot, val_accuracy_plot, label = "Val Accuracy plot")
    plt.xlabel('Epochs')

    plt.legend()
    plt.show()

  plt.plot(epochs_plot, loss_plot, label = "Loss plot")
  plt.plot(epochs_plot, val_loss_plot, label = "Val Loss plot")

  plt.legend()
  plt.show()

PATHL = '/content/drive/My Drive/Stance Detection/logistic{}.pt'
PATHS = '/content/drive/My Drive/Stance Detection/conv_model{}.pt'

siamese_disagrees_agrees = ConvEmbed()
epochs_plot, loss_plot, val_loss_plot = train_dist_embeddings(siamese_disagrees_agrees, 1, PATHS, 5)
plot(epochs_plot, loss_plot, val_loss_plot)

logistic_disagrees_agrees = Classifier()
epochs_plot, accuracy_plot, loss_plot, val_accuracy_plot, val_loss_plot = train_logistic_regression(logistic_disagrees_agrees, 1, PATHS, PATHL, 4, False)
plot(epochs_plot, loss_plot, val_loss_plot, accuracy_plot, val_accuracy_plot)

siamese_agrees_discusses = ConvEmbed()
epochs_plot, loss_plot, val_loss_plot = train_dist_embeddings(siamese_agrees_discusses, 2, PATHS, 7)
plot(epochs_plot, loss_plot, val_loss_plot)

logistic_agrees_discusses = Classifier()
epochs_plot, accuracy_plot, loss_plot, val_accuracy_plot, val_loss_plot = train_logistic_regression(logistic_agrees_discusses, 2, PATHS, PATHL, 5, False)
plot(epochs_plot, loss_plot, val_loss_plot, accuracy_plot, val_accuracy_plot)

def test_logistic_regression(neg_idx, PATHS, PATHL, conv=False):
  if conv:
    siamese = ConvEmbed()
  else:
    siamese = PoolerFC()
  siamese.load_state_dict(torch.load(PATHS.format(neg_idx), map_location=device))
  siamese.to(device)
  siamese.eval()

  model = Classifier()
  model.load_state_dict(torch.load(PATHL.format(neg_idx), map_location=device))
  model.to(device)
  model.eval()
  bce_loss = nn.BCELoss()
  # optimizer = AdamW(model.parameters(), lr=0.1)
  # scheduler = lr_scheduler.StepLR(optimizer, step_size=ceil(ep/2), gamma=0.1)

  PATH_TEST_STANCES = '/content/drive/My Drive/Stance Detection/dataset/test_stances.csv'
  PATH_TEST_BODIES = '/content/drive/My Drive/Stance Detection/dataset/test_bodies.csv'

  progress = tqdm.tqdm(total=2587, position=0, leave=True)

  with torch.no_grad():
    running_loss = 0
    iterations = 0
    correct = 0
    pos = 0
    neg = 0
    total = 0
    total_pos = 0
    total_neg = 0
    d = DatasetIterator(PATH_TEST_STANCES, PATH_TEST_BODIES, False, 0, 2587)
    while True:
      dataloader = d.next(progress)
      if dataloader is None:
        break
      for body_id, headEmbedding, bodyEmbedding, stance, headline_id in dataloader:
        if conv:
          body = bodyEmbedding.squeeze(0).to(device)
          head = headEmbedding.squeeze(0).to(device)
        else:
          body = bodyPooler.squeeze(0)
          head = headPooler.squeeze(0)

        stance = stance.squeeze(0)
        
        positives = []
        negatives = []

        for idx in range(len(stance)):
          if stance[idx] == neg_idx:
            negatives.append(head[idx].unsqueeze(0))
          elif stance[idx] > neg_idx:
            positives.append(head[idx].unsqueeze(0))

        # print(len(positives))
        # print(len(negatives))

        total_pos += len(positives)
        total_neg += len(negatives)

        if len(negatives):
          # model.zero_grad()
          # optimizer.zero_grad()
          # print(negativePooler.shape)
          if conv:
            bodyN = body.repeat(len(negatives), 1, 1, 1).to(device)
            negative = torch.stack(negatives).to(device)
          else:
            negativePooler = torch.cat(negatives)
            bodyPoolerN = bodyPooler.repeat(len(negatives), 1)

          label = torch.zeros(len(negatives), 1, device=device)

          embed1 = siamese.forward(bodyN)
          embed2 = siamese.forward(negative)
          # print('Negative:')
          # print(cos(embed1, embed2))
          # dist = []
          # for i in range(embed1.shape[0]):
          #   dist.append(torch.dist(embed1[i], embed2[i]))
          # print(torch.as_tensor(dist))
          output = model(embed1, embed2)
          loss = bce_loss(output, label)

          # loss.backward()
          # optimizer.step()
          running_loss += loss.item()
          output[output >= 0.5] = 1
          output[output < 0.5] = 0
          neg += torch.sum(torch.eq(output, label)).item()
          iterations += 1

        if len(positives):
          # model.zero_grad()
          # optimizer.zero_grad()
          # print(positivePooler.shape)
          if conv:
            bodyN = body.repeat(len(positives), 1, 1, 1).to(device)
            positive = torch.stack(positives).to(device)
          else:
            positivePooler = torch.cat(positives)
            bodyPoolerN = bodyPooler.repeat(len(positives), 1)
          label = torch.ones(len(positives), 1, device=device)

          embed1 = siamese.forward(bodyN)
          embed2 = siamese.forward(positive)
          # print('Positive: ')
          # print(cos(embed1, embed2))
          # dist = []
          # for i in range(embed1.shape[0]):
          #   dist.append(torch.dist(embed1[i], embed2[i]))
          # print(torch.as_tensor(dist))
          output = model(embed1, embed2)
          # print(output)
          # print(label)
          loss = bce_loss(output, label)

          # loss.backward()
          # optimizer.step()
          running_loss += loss.item()
          output[output >= 0.5] = 1
          output[output < 0.5] = 0
          pos += torch.sum(torch.eq(output, label)).item()
        # print('\n')
    print(f"\nModel : {neg_idx}")
    print(f"Training loss : {running_loss} / {total_neg + total_pos} ")
    print(f"Accuracy Pos : {pos} / {total_pos} : ", pos / total_pos)
    print(f"Accuracy Neg : {neg} / {total_neg} : ", neg / total_neg)
    # scheduler.step()

PATHL = '/content/drive/My Drive/Stance Detection/logistic{}.pt'
PATHS = '/content/drive/My Drive/Stance Detection/conv_model{}.pt'

test_logistic_regression(2, PATHS, PATHL, True)

test_logistic_regression(1, PATHS, PATHL, True)